# 🧠 我的论文阅读笔记总览

本页面整理了我阅读和总结过的论文笔记，包含关键词、PDF、本地笔记等信息。

---

## 📚 论文列表

| 标题 |  关键词 | 笔记 |
|------|------|------|
| ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions| 多尺度适配器（Multi-scale Adapter）、文本引导掩码损失（Text-Guided Masking Loss）、匹配损失（Matching Loss）、内上下文对齐（Intra-Contextual Alignment）、跨上下文编码器（Inter-Context Encoder）、对比学习优化（Contrastive Learning）、双上下文对齐（Doubly Contextual Alignment） | [📘](note/ContextBLIP.md) |
|ColPali: Efficient Document Retrieval with Vision Language Models|Contextualized Late Interaction, Query-to-Page Matching, OCR-free Document Understanding, Patch-level Relevance Identification, Visual-Semantic Embedding, Multimodal Document Retrieval, Dense Passage Retrieval with Vision, Cross-modal Semantic Alignment, Document Layout Analysis, Vision-Language Model Pretraining|[📘](note/CoPail.md)|
|GOAL: Global-local Object Alignment Learning|Local Image-Sentence Matching (LISM)、Token Similarity-based Learning (TSL)、Text-Guided Masking Loss、Inter-Context Encoder、Multi-scale Adapter、Token-level Alignment、Cross-modal Attention Propagation、Contrastive Learning for Local-Global Pairs|[📘](note/Global-Local-alignment.md) |
|An Image is Worth More Than 16×16 Patches: Exploring Transformers on Individual Pixels|像素作为token（Pixels-as-tokens）、无局部性偏置（Locality-free）、位置嵌入（Learned Position Embedding）、对比学习优化（Contrastive Learning）、注意力机制（Self-Attention）、块化设计（Patchification）、像素置换（Pixel Permutation）、多尺度分析（Multi-scale Analysis）|[📘](note/imageMore16.md)|  
|LaTr: Layout-Aware Transformer for Scene-Text VQA  |Layout-Aware Pre-Training (LAP), Text-Guided Masking Loss, Cross-Modal Attention Propagation, OCR Token Projection, 2-D Spatial Embedding, Inter-Context Encoder, Vision Transformer (ViT) ,Layout Position Embedding, Token-Level Alignment, Vocabulary-Free Decoding, Denoising Pre-Training|[📘](note/LaTr.md)|  
|Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA |Pointer-Augmented Multimodal Transformer (M4C)、Denoising Pre-Training、Vocabulary-Free Decoding,OCR Token Projection、2-D Spatial Embedding、Inter-Context Encoder、Vision Transformer (ViT),Layout Position Embedding、Token-Level Alignment、Dynamic Pointer Network、Cross-Modal Attention Propagation |[📘](note/M4C.md)|  
|Multimodal Alignment and Fusion: A Survey|Cross-modal Feature Alignment, Token-level Alignment, Kernel-based Fusion, Graph-based Multimodal Fusion, Attention Bottlenecks, Visual Instruction Tuning, Condition-aware Multimodal Fusion, Adaptive Embedded Fusion, Early/Late/Hybrid Fusion, Multiway Transformer, Dynamic Time Warping, Q-Former|[📘](note/Multi-fusion.md)|  
|Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications| DropToken Strategy, Multiway Transformer, Cross-Attention Adapter, Image-Text Contrastive Loss, Masked "Language" Modeling, Two-stage Training, Pre-training Multi-task Training, Instruction Fine-tuning, Visual Question Answering (VQA), Multimodal Abstractive Summarization, Multimodal Information Retrieval, Hierarchical Attention Fusion|[📘](note/Multi-representation.md)|  
|MUVERA: Multi-Vector Retrieval via Fixed Dimensional Encodings|Fixed Dimensional Encodings (FDE), Asymmetric Encoding, Token-level Retrieval, Single-Vector Heuristic, Chamfer Similarity, MIPS Solvers, Multi-vector Similarity Search, Light-weight Retrieval Mechanism|[📘](note/Multi-vector-retrieval.md)|  
|RAPTOR: RECURSIVE ABSTRACTIVE PROCESSING FOR TREE-ORGANIZED RETRIEVAL|Tree-Organized Retrieval, Recursive Clustering, Hierarchical Summarization, Multi-level Abstraction, Chunk Embedding, Context-aware Retrieval, Abstract Node Generation, Bottom-up Tree Construction, Query-adaptive Retrieval, Long Document Understanding|[📘](note/PAPTOR.md)|  
|End-to-end Knowledge Retrieval with Multi-modal Queries|ReViz Model, ReMuQ Dataset, Multi-modal Queries, End-to-end VL-Retriever, Multimodal Retrieval Pre-training Task, Cross-modal Semantic Alignment, Image-Text Query Processing, Knowledge Corpus Retrieval, VL-ICT Pretraining|[📘](note/Reviz-multi-queries.md)|  
|A Survey on Multimodal Retrieval-Augmented Generation|伪MRAG架构、OCR-Text Graph、跨页问题处理机制、无答案问题检测模块、向量数据库检索、对比学习优化、多模态嵌入模型、文档解析模块、多模态检索模块、生成模块  |[📘](note/survey-RAG.md)|    
|Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion|Semantic Interaction-guided Module, Degradation-aware Processing, Text-guided Image Restoration, Text Semantic Encoder, Semantic Interaction Fusion Decoder, Interactive Flexible Fusion, Text-to-Fusion Mapping, Degradation Specification, Multi-modal Image Fusion, Object Detection Enhancement|[📘](note/Text-IF.md)|  
|TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation|Discrete-to-Continuous Visual Tokenizer, Vector-Quantized (VQ) Token Semanticization, CLIP-Level Semantic Integration, Multimodal Comprehension-Generation Disentanglement, End-to-End Autoregressive Training, Semanticized VQ Tokens, Token-CLIP Fusion Mechanism, Multimodal Understanding Enhancement, Visual Token Quantization, Token-level Semantic Alignment|[📘](note/ToKLIP.md)|  
|ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval|Scene Text Aware Cross-modal Retrieval, Vision and Scene Text Aggregation, Full Transformer Architecture, Scene Text Semantics Integration, Cross-modal Entity Alignment, Text-Visual Feature Fusion, Scene Text Graph, Text-guided Attention Mechanism, Multi-granularity Text Representation, OCR-Text Graph|[📘](note/ViSTA.md)|  
|Visual-Linguistic Dependency Encoding for Image-Text Retrieval| Visual-Linguistic Dependency Encoding, Linguistic Dependency Information, Cross-modal Semantic Alignment, Image-Text Retrieval, Dependency Structure Modeling, Visual Region Interaction, Multi-granular Semantic Enhancement, Direction-Oriented Embedding, Context-aware Multi-view Summarization, Directional Visual-Semantic Embedding|[📘](note/Visual-Linguistic dependency.md)|  
|Efficient Large Language Models: A Survey|Model Compression, Unstructured Pruning, Knowledge Distillation, Prompt Tuning, Memory-Efficient Fine-Tuning, Speculative Decoding, KV-Cache Optimization, Sharing-based Attention, MQA (Multi-Query Attention), GQA (Grouped-Query Attention), Performer, RFA (Random Features Attention), Low-Rank Approximation|[📘](note/Efficient_Attention_Survey.md)| 
|ALPS: Attention Localization and Pruning Strategy for Efficient Alignment of Large Language Models| Task-specific attention heads localization, Attention head pruning, Parameter-efficient fine-tuning, Transferable task-specific heads, Knowledge forgetting mitigation, Layer consistency selection, QKV weight matrices|[📘](note/Attention_Localization_and_Pruning_Strategy.md)|  
|How LLMs and Humans Trade Compression for Meaning|Semantic Compression, Conceptual Structures, Cognitive Manageability, Token-to-Thought Mapping, Fine-grained Semantic Nuances, Category Abstraction, Pattern Matching Limitations, Semantic Richness, Conceptual Alignment, Compression-Generation Tradeoff|[📘](note/Trade_Compression_for_Meaning.md)|  
|------|------|[📘]()|  
|------|------|[📘]()|  






---

## 📁 文件结构
roject/
│
├── README.md ← 论文总览目录页
│
├── notes/ ← 存放所有 md 格式笔记
│ ├── 1.md
│ ├── 2.md
│ └── ...
│
└── paper/ ← 存放 PDF 文件
├── 1.pdf
├── 2.pdf
└── ...


