# ğŸ§  æˆ‘çš„è®ºæ–‡é˜…è¯»ç¬”è®°æ€»è§ˆ

æœ¬é¡µé¢æ•´ç†äº†æˆ‘é˜…è¯»å’Œæ€»ç»“è¿‡çš„è®ºæ–‡ç¬”è®°ï¼ŒåŒ…å«å…³é”®è¯ã€PDFã€æœ¬åœ°ç¬”è®°ç­‰ä¿¡æ¯ã€‚

---

## ğŸ“š è®ºæ–‡åˆ—è¡¨

| æ ‡é¢˜ |  å…³é”®è¯ | ç¬”è®° |
|------|------|------|
| ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval from Linguistically Complex Descriptions| å¤šå°ºåº¦é€‚é…å™¨ï¼ˆMulti-scale Adapterï¼‰ã€æ–‡æœ¬å¼•å¯¼æ©ç æŸå¤±ï¼ˆText-Guided Masking Lossï¼‰ã€åŒ¹é…æŸå¤±ï¼ˆMatching Lossï¼‰ã€å†…ä¸Šä¸‹æ–‡å¯¹é½ï¼ˆIntra-Contextual Alignmentï¼‰ã€è·¨ä¸Šä¸‹æ–‡ç¼–ç å™¨ï¼ˆInter-Context Encoderï¼‰ã€å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ï¼ˆContrastive Learningï¼‰ã€åŒä¸Šä¸‹æ–‡å¯¹é½ï¼ˆDoubly Contextual Alignmentï¼‰ | [ğŸ“˜](note/ContextBLIP.md) |
|ColPali: Efficient Document Retrieval with Vision Language Models|Contextualized Late Interaction, Query-to-Page Matching, OCR-free Document Understanding, Patch-level Relevance Identification, Visual-Semantic Embedding, Multimodal Document Retrieval, Dense Passage Retrieval with Vision, Cross-modal Semantic Alignment, Document Layout Analysis, Vision-Language Model Pretraining|[ğŸ“˜](note/CoPail.md)|
|GOAL: Global-local Object Alignment Learning|Local Image-Sentence Matching (LISM)ã€Token Similarity-based Learning (TSL)ã€Text-Guided Masking Lossã€Inter-Context Encoderã€Multi-scale Adapterã€Token-level Alignmentã€Cross-modal Attention Propagationã€Contrastive Learning for Local-Global Pairs|[ğŸ“˜](note/Global-Local-alignment.md) |
|An Image is Worth More Than 16Ã—16 Patches: Exploring Transformers on Individual Pixels|åƒç´ ä½œä¸ºtokenï¼ˆPixels-as-tokensï¼‰ã€æ— å±€éƒ¨æ€§åç½®ï¼ˆLocality-freeï¼‰ã€ä½ç½®åµŒå…¥ï¼ˆLearned Position Embeddingï¼‰ã€å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ï¼ˆContrastive Learningï¼‰ã€æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰ã€å—åŒ–è®¾è®¡ï¼ˆPatchificationï¼‰ã€åƒç´ ç½®æ¢ï¼ˆPixel Permutationï¼‰ã€å¤šå°ºåº¦åˆ†æï¼ˆMulti-scale Analysisï¼‰|[ğŸ“˜](note/imageMore16.md)|  
|LaTr: Layout-Aware Transformer for Scene-Text VQA  |Layout-Aware Pre-Training (LAP), Text-Guided Masking Loss, Cross-Modal Attention Propagation, OCR Token Projection, 2-D Spatial Embedding, Inter-Context Encoder, Vision Transformer (ViT) ,Layout Position Embedding, Token-Level Alignment, Vocabulary-Free Decoding, Denoising Pre-Training|[ğŸ“˜](note/LaTr.md)|  
|Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA |Pointer-Augmented Multimodal Transformer (M4C)ã€Denoising Pre-Trainingã€Vocabulary-Free Decoding,OCR Token Projectionã€2-D Spatial Embeddingã€Inter-Context Encoderã€Vision Transformer (ViT),Layout Position Embeddingã€Token-Level Alignmentã€Dynamic Pointer Networkã€Cross-Modal Attention Propagation |[ğŸ“˜](note/M4C.md)|  
|Multimodal Alignment and Fusion: A Survey|Cross-modal Feature Alignment, Token-level Alignment, Kernel-based Fusion, Graph-based Multimodal Fusion, Attention Bottlenecks, Visual Instruction Tuning, Condition-aware Multimodal Fusion, Adaptive Embedded Fusion, Early/Late/Hybrid Fusion, Multiway Transformer, Dynamic Time Warping, Q-Former|[ğŸ“˜](note/Multi-fusion.md)|  
|Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications| DropToken Strategy, Multiway Transformer, Cross-Attention Adapter, Image-Text Contrastive Loss, Masked "Language" Modeling, Two-stage Training, Pre-training Multi-task Training, Instruction Fine-tuning, Visual Question Answering (VQA), Multimodal Abstractive Summarization, Multimodal Information Retrieval, Hierarchical Attention Fusion|[ğŸ“˜](note/Multi-representation.md)|  
|MUVERA: Multi-Vector Retrieval via Fixed Dimensional Encodings|Fixed Dimensional Encodings (FDE), Asymmetric Encoding, Token-level Retrieval, Single-Vector Heuristic, Chamfer Similarity, MIPS Solvers, Multi-vector Similarity Search, Light-weight Retrieval Mechanism|[ğŸ“˜](note/Multi-vector-retrieval.md)|  
|RAPTOR: RECURSIVE ABSTRACTIVE PROCESSING FOR TREE-ORGANIZED RETRIEVAL|Tree-Organized Retrieval, Recursive Clustering, Hierarchical Summarization, Multi-level Abstraction, Chunk Embedding, Context-aware Retrieval, Abstract Node Generation, Bottom-up Tree Construction, Query-adaptive Retrieval, Long Document Understanding|[ğŸ“˜](note/PAPTOR.md)|  
|End-to-end Knowledge Retrieval with Multi-modal Queries|ReViz Model, ReMuQ Dataset, Multi-modal Queries, End-to-end VL-Retriever, Multimodal Retrieval Pre-training Task, Cross-modal Semantic Alignment, Image-Text Query Processing, Knowledge Corpus Retrieval, VL-ICT Pretraining|[ğŸ“˜](note/Reviz-multi-queries.md)|  
|A Survey on Multimodal Retrieval-Augmented Generation|ä¼ªMRAGæ¶æ„ã€OCR-Text Graphã€è·¨é¡µé—®é¢˜å¤„ç†æœºåˆ¶ã€æ— ç­”æ¡ˆé—®é¢˜æ£€æµ‹æ¨¡å—ã€å‘é‡æ•°æ®åº“æ£€ç´¢ã€å¯¹æ¯”å­¦ä¹ ä¼˜åŒ–ã€å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ã€æ–‡æ¡£è§£ææ¨¡å—ã€å¤šæ¨¡æ€æ£€ç´¢æ¨¡å—ã€ç”Ÿæˆæ¨¡å—  |[ğŸ“˜](note/survey-RAG.md)|    
|Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion|Semantic Interaction-guided Module, Degradation-aware Processing, Text-guided Image Restoration, Text Semantic Encoder, Semantic Interaction Fusion Decoder, Interactive Flexible Fusion, Text-to-Fusion Mapping, Degradation Specification, Multi-modal Image Fusion, Object Detection Enhancement|[ğŸ“˜](note/Text-IF.md)|  
|TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation|Discrete-to-Continuous Visual Tokenizer, Vector-Quantized (VQ) Token Semanticization, CLIP-Level Semantic Integration, Multimodal Comprehension-Generation Disentanglement, End-to-End Autoregressive Training, Semanticized VQ Tokens, Token-CLIP Fusion Mechanism, Multimodal Understanding Enhancement, Visual Token Quantization, Token-level Semantic Alignment|[ğŸ“˜](note/ToKLIP.md)|  
|ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval|Scene Text Aware Cross-modal Retrieval, Vision and Scene Text Aggregation, Full Transformer Architecture, Scene Text Semantics Integration, Cross-modal Entity Alignment, Text-Visual Feature Fusion, Scene Text Graph, Text-guided Attention Mechanism, Multi-granularity Text Representation, OCR-Text Graph|[ğŸ“˜](note/ViSTA.md)|  
|Visual-Linguistic Dependency Encoding for Image-Text Retrieval| Visual-Linguistic Dependency Encoding, Linguistic Dependency Information, Cross-modal Semantic Alignment, Image-Text Retrieval, Dependency Structure Modeling, Visual Region Interaction, Multi-granular Semantic Enhancement, Direction-Oriented Embedding, Context-aware Multi-view Summarization, Directional Visual-Semantic Embedding|[ğŸ“˜](note/Visual-Linguistic dependency.md)|  
|Efficient Large Language Models: A Survey|Model Compression, Unstructured Pruning, Knowledge Distillation, Prompt Tuning, Memory-Efficient Fine-Tuning, Speculative Decoding, KV-Cache Optimization, Sharing-based Attention, MQA (Multi-Query Attention), GQA (Grouped-Query Attention), Performer, RFA (Random Features Attention), Low-Rank Approximation|[ğŸ“˜](note/Efficient_Attention_Survey.md)| 
|ALPS: Attention Localization and Pruning Strategy for Efficient Alignment of Large Language Models| Task-specific attention heads localization, Attention head pruning, Parameter-efficient fine-tuning, Transferable task-specific heads, Knowledge forgetting mitigation, Layer consistency selection, QKV weight matrices|[ğŸ“˜](note/Attention_Localization_and_Pruning_Strategy.md)|  
|How LLMs and Humans Trade Compression for Meaning|Semantic Compression, Conceptual Structures, Cognitive Manageability, Token-to-Thought Mapping, Fine-grained Semantic Nuances, Category Abstraction, Pattern Matching Limitations, Semantic Richness, Conceptual Alignment, Compression-Generation Tradeoff|[ğŸ“˜](note/Trade_Compression_for_Meaning.md)|  
|------|------|[ğŸ“˜]()|  
|------|------|[ğŸ“˜]()|  






---

## ğŸ“ æ–‡ä»¶ç»“æ„
roject/
â”‚
â”œâ”€â”€ README.md â† è®ºæ–‡æ€»è§ˆç›®å½•é¡µ
â”‚
â”œâ”€â”€ notes/ â† å­˜æ”¾æ‰€æœ‰ md æ ¼å¼ç¬”è®°
â”‚ â”œâ”€â”€ 1.md
â”‚ â”œâ”€â”€ 2.md
â”‚ â””â”€â”€ ...
â”‚
â””â”€â”€ paper/ â† å­˜æ”¾ PDF æ–‡ä»¶
â”œâ”€â”€ 1.pdf
â”œâ”€â”€ 2.pdf
â””â”€â”€ ...


